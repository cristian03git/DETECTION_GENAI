{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Per Dataset di Train"
   ],
   "metadata": {
    "id": "S0fza-C_pGWf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Librerie\n",
    "E' necessario importare delle librerie, che permettono di effettuare determinate operazioni:\n",
    "  1. Importare il modulo `drive`, per accedere a Google Drive da Google Colab, per usarlo come disco;\n",
    "  2. Importare la libreria `pandas`, per la manipolazione dei dati tabellari e gestione di **DataFrame**;\n",
    "  3. Importare il modulo `files`, per permettere il download del file dal Colab sul computer locale."
   ],
   "metadata": {
    "id": "S7g1SiF0yjtG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive #[1]\n",
    "import pandas as pd #[2]\n",
    "from google.colab import files #[3]"
   ],
   "metadata": {
    "id": "HAk8VDLNyxIJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Montaggio Drive\n",
    "Viene aperta una finestra per fare l'**autenticazione a Google** e accedere ai file da Colab.<br>Monta Drive nella directory `/content/drive`."
   ],
   "metadata": {
    "id": "KMAU7YGIdmM7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "hktZ6MoNeE96"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definizione del percorso e dei file da caricare\n",
    "  1. Viene specificata la cartella in cui si trovano i file da elaborare, tramite un determinato `base_path`;\n",
    "  2. Viene costruita una lista di file, nel formato `.parquet`, da unire; quest'ultimi sono partizioni dello stesso dataset di TRAIN preso in questione (https://huggingface.co/datasets/Jinyan1/COLING_2025_MGT_multingual/viewer/default/train)."
   ],
   "metadata": {
    "id": "u1OS8mJXpG3e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_path = \"/content/drive/MyDrive/TESI - Classificazione/MIO/partizioni_dt\" #[1]\n",
    "paths = [\n",
    "    f\"{base_path}/train-00000-of-00003.parquet\",\n",
    "    f\"{base_path}/train-00001-of-00003.parquet\",\n",
    "    f\"{base_path}/train-00002-of-00003.parquet\"\n",
    "] #[2]"
   ],
   "metadata": {
    "id": "w2bkJtIlr4Jd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Caricamento dei file e Unione\n",
    "  1. Viene caricato ogni file `.parquet` in un **DataFrame** separato;\n",
    "  2. Vengono uniti tutti i DataFrame in _uno solo_ (`df_full`).<br> `ignore_index=True` fa in modo che l'indice sia rigenerato da zero."
   ],
   "metadata": {
    "id": "NmlaBGPztCIC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Caricamento dei file Parquet...\") #Messaggio per l'utente\n",
    "df_list = [pd.read_parquet(path) for path in paths]  #[1]:Lettura di ogni file\n",
    "df_full = pd.concat(df_list, ignore_index=True)  #[2]:Unione di tutti i DataFrame\n"
   ],
   "metadata": {
    "id": "s6C7LRlQun9J"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizzazione lingue e Input utente\n",
    "  1. Estrazione di tutti i valori unici della colonna `\"lang\"`, ignorando eventuali NaN (_Not a Number_);\n",
    "  2. Vengono stampate le lingue presenti nel dataset.\n",
    "  3. Viene chiesto all'utente di scegliere una **lingua valida tra quelle elencate**, ripetendo la richiesta fino a quando non viene fornito un input corretto.\n",
    "\n"
   ],
   "metadata": {
    "id": "Ml2-hV8fwcyE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lingue_disponibili = df_full[\"lang\"].dropna().unique().tolist()  #[1]\n",
    "print(\"Lingue disponibili nel dataset:\")\n",
    "print(lingue_disponibili) #[2]\n",
    "\n",
    "#[3]:\n",
    "lingua_scelta = \"\"\n",
    "while lingua_scelta not in lingue_disponibili:\n",
    "    lingua_scelta = input(\"Inserisci una delle lingue disponibili (es. 'it', 'en', ecc.): \").strip()\n",
    "    if lingua_scelta not in lingue_disponibili:\n",
    "        print(\"Lingua non valida. Riprova.\")"
   ],
   "metadata": {
    "id": "fvCiVAGSwrAq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtraggio del Dataframe\n",
    "  1. Creazione di un nuovo DataFrame contenente _SOLO LE RIGHE NELLA LINGUA SELEZIONATA_;\n",
    "  2. Viene effettuata la stampa del numero di righe filtrate."
   ],
   "metadata": {
    "id": "1EgjMXfhyLKj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Filtraggio della lingua: {lingua_scelta}...\")\n",
    "df_lang = df_full[df_full[\"lang\"] == lingua_scelta]  #[1]\n",
    "print(f\"Totale righe per la lingua '{lingua_scelta}': {len(df_lang)}\") #[2]"
   ],
   "metadata": {
    "id": "m_i8zd4Vzib2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Salvataggio e Download\n",
    "  1. Viene costruito il percorso e il nome del file `.csv` da salvare, includendo la lingua nel nome;\n",
    "  2. Salvataggio del Dataframe filtrato in formato CSV su Google Drive. <br> `index=False` permette di evitare il salvataggio della colonna indice;\n",
    "  3. Avvio del download del file CSV sul computer dell'utente."
   ],
   "metadata": {
    "id": "N7N-DtIM0Etk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "output_csv = f\"/content/drive/MyDrive/TESI - Classificazione/MIO/{lingua_scelta}_train_full.csv\" #[1]\n",
    "df_lang.to_csv(output_csv, index=False)  #[2]\n",
    "print(f\"File CSV salvato come: {output_csv}\") #Messaggio per l'utente\n",
    "files.download(output_csv) #[3]"
   ],
   "metadata": {
    "id": "3MsAZd8EuZmp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Per Dataset di Dev\n"
   ],
   "metadata": {
    "id": "fg-qfFwZpVI1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Librerie\n",
    "E' necessario importare delle librerie, che permettono di effettuare determinate operazioni:\n",
    "  1. Importare il modulo `drive`, per accedere a Google Drive da Google Colab, per usarlo come disco;\n",
    "  2. Importare la libreria `pandas`, per la manipolazione dei dati tabellari e gestione di **DataFrame**;\n",
    "  3. Importare il modulo `files`, per permettere il download del file dal Colab sul computer locale."
   ],
   "metadata": {
    "id": "2d4Jn8IyqQ8I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive #[1]\n",
    "import pandas as pd #[2]\n",
    "from google.colab import files #[3]"
   ],
   "metadata": {
    "id": "4SA10DQyqUIB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Montaggio Drive\n",
    "Viene aperta una finestra per fare l'**autenticazione a Google** e accedere ai file da Colab.<br>Monta Drive nella directory `/content/drive`."
   ],
   "metadata": {
    "id": "btdNQlBlqgJT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "p76CxJOhqlSN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definizione del percorso e dei file da caricare\n",
    "  1. Viene specificata la cartella in cui si trovano i file da elaborare, tramite un determinato `base_path`;\n",
    "  2. Viene costruita una lista di file, nel formato `.parquet`, da unire; quest'ultimi sono partizioni dello stesso dataset di DEV preso in questione (https://huggingface.co/datasets/Jinyan1/COLING_2025_MGT_multingual/viewer/default/dev)."
   ],
   "metadata": {
    "id": "FoE6r3O6qoSH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_path = \"/content/drive/MyDrive/TESI - Classificazione/MIO/partizioni_dt\" #[1]\n",
    "paths = [\n",
    "    f\"{base_path}/dev-00000-of-00001.parquet\"\n",
    "] #[2]"
   ],
   "metadata": {
    "id": "KV-dMy4Yq7lx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Caricamento dei file e Unione\n",
    "  1. Viene caricato ogni file `.parquet` in un **DataFrame** separato;\n",
    "  2. Vengono uniti tutti i DataFrame in _uno solo_ (`df_full`).<br> `ignore_index=True` fa in modo che l'indice sia rigenerato da zero."
   ],
   "metadata": {
    "id": "g95ie4LCrT01"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Caricamento dei file Parquet...\") #Messaggio per l'utente\n",
    "df_list = [pd.read_parquet(path) for path in paths]  #[1]:Lettura di ogni file\n",
    "df_full = pd.concat(df_list, ignore_index=True)  #[2]:Unione di tutti i DataFrame"
   ],
   "metadata": {
    "id": "CpyLvZFerXlL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizzazione lingue e Input utente\n",
    "  1. Estrazione di tutti i valori unici della colonna `\"lang\"`, ignorando eventuali NaN (_Not a Number_);\n",
    "  2. Vengono stampate le lingue presenti nel dataset.\n",
    "  3. Viene chiesto all'utente di scegliere una **lingua valida tra quelle elencate**, ripetendo la richiesta fino a quando non viene fornito un input corretto."
   ],
   "metadata": {
    "id": "ja67D_jOuyyV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lingue_disponibili = df_full[\"lang\"].dropna().unique().tolist()  #[1]\n",
    "print(\"Lingue disponibili nel dataset:\")\n",
    "print(lingue_disponibili) #[2]\n",
    "\n",
    "#[3]:\n",
    "lingua_scelta = \"\"\n",
    "while lingua_scelta not in lingue_disponibili:\n",
    "    lingua_scelta = input(\"Inserisci una delle lingue disponibili (es. 'it', 'en', ecc.): \").strip()\n",
    "    if lingua_scelta not in lingue_disponibili:\n",
    "        print(\"Lingua non valida. Riprova.\")"
   ],
   "metadata": {
    "id": "OA7ogdQQuzn_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtraggio del Dataframe\n",
    "  1. Creazione di un nuovo DataFrame contenente _SOLO LE RIGHE NELLA LINGUA SELEZIONATA_;\n",
    "  2. Viene effettuata la stampa del numero di righe filtrate."
   ],
   "metadata": {
    "id": "_WDzgvDMrcZT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Filtraggio della lingua: {lingua_scelta}...\")\n",
    "df_lang = df_full[df_full[\"lang\"] == lingua_scelta]  #[1]\n",
    "print(f\"Totale righe per la lingua '{lingua_scelta}': {len(df_lang)}\") #[2]"
   ],
   "metadata": {
    "id": "XXEhVZQsrhCJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Salvataggio e Download\n",
    "  1. Viene costruito il percorso e il nome del file `.csv` da salvare, includendo la lingua nel nome;\n",
    "  2. Salvataggio del Dataframe filtrato in formato CSV su Google Drive. <br> `index=False` permette di evitare il salvataggio della colonna indice;\n",
    "  3. Avvio del download del file CSV sul computer dell'utente."
   ],
   "metadata": {
    "id": "l_uqUDVWrj5O"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "output_csv = f\"/content/drive/MyDrive/TESI - Classificazione/MIO/{lingua_scelta}_dev_full.csv\" #[1]\n",
    "df_lang.to_csv(output_csv, index=False)  #[2]\n",
    "print(f\"File CSV salvato come: {output_csv}\") #Messaggio per l'utente\n",
    "files.download(output_csv) #[3]"
   ],
   "metadata": {
    "id": "Ob72Ut8ouYwu"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}